Inside you directory:

> kubectl apply -f rbac.yaml
> kubectl apply -f deployment.yaml ---->for first time then else use the below
> kubectl rollout restart deployment k8s-error-agent-dev

copy the files into the pod
> kubectl cp main.py k8s-error-agent-dev-6579b68854-gcm9b:app/main.py 
> kubectl cp requirements.txt k8s-error-agent-dev-6579b68854-gcm9b:/app/requirements.txt

# If you have other files, copy them too 
> kubectl cp kube-action.py k8s-error-agent-dev-6579b68854-gcm9b:/app/kube-action.py

>Install dependencies and run:
bash
# Access the pod shell
> kubectl exec -it k8s-error-agent-dev-6579b68854-gcm9b -- /bin/bash



# Inside the pod:
> cd /app
> pip install -r requirements.txt                           -----install requirements inside the pod

for helm:
> apt-get update && apt-get install -y curl gnupg2
> curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
> chmod 700 get_helm.sh 
> ./get_helm.sh 
> rm get_helm.sh
> helm version                          ----to verify if its installed.

> python -u main.py           ----run the file                                                                            -----to run the agent


>When you make code changes:
>>kubectl cp main.py k8s-error-agent-dev-XXXXX:/app/main.py
>> kubectl exec k8s-error-agent-dev-XXXXX -- pkill python  # restart your app If its running
>>kubectl exec -it k8s-error-agent-dev-XXXXX -- python -u /app/main.py 2>&1 | tee /proc/1/fd/1  (# 2>&1 | tee /proc/1/fd/1   to make this and pod logs show parallely)

minikube service service_name # it will expose in localhost.
kubectl port-forward service/example-webapp-service 8080:80

helm upgrade nginx-1 bitnami/nginx --set updateStrategy.type=Recreate --set updateStrategy.rollingUpdate=null --set image.repository=busybox --set image.tag=latest --set global.security.allowInsecureImages=true

we will do one thing lets create seperate process/threads
process 1: checks for failed pods and does rollback the revision in cm no need to wait to get new revision 
process 2: checks for helm charts install/ upgrade 
waits for 30s to determine if pod up and running then keep it in cm, it needs to check for the stabilty irrespective of process1, 

basically exact previous code functionality but divide them into 2 seperate threads processing parellely 

this will atleast make sure to check the pod health in more robust and tell the revision is stable or not more perfectly so that process1 will rollback to correct stable revision
